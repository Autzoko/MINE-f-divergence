{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:21<00:00, 4656.44it/s]\n",
      "100%|██████████| 100000/100000 [00:26<00:00, 3741.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4810719675338408"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Sample_Gibbs_from_Gaussian import log_P\n",
    "from Sample_Gibbs_from_Gaussian import sample_w\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "sample_size = 100000\n",
    "p_current = 4\n",
    "beta = 10\n",
    "sigma_q = 0.5\n",
    "################################################################\n",
    "original_random_state = np.random.get_state()\n",
    "np.random.seed(20230929)\n",
    "#gaussian distribution sampler: normal(mean=0.0, variance_sqrt=1.0, size=None) s = np.random.normal(0,1)\n",
    "#teacher model\n",
    "#dimension of x: d（固定不变）10->5\n",
    "d = 5\n",
    "#number of training samples（固定不变）100->20\n",
    "N = 20\n",
    "#dimension of hypothesis space\n",
    "p0 = 5 #dimension of teacher model（固定不变）\n",
    "p = p_current #dimension of student model（可变）#p=200\n",
    "p_max = 2000 #upper bound of dimension of student model（固定不变）\n",
    "#point-wise activate function f:tanh\n",
    "#variance of random noise added to y\n",
    "sigma = 0.1\n",
    "\n",
    "#random feature matrix\n",
    "F0 = np.random.normal(0,1,(d,p0)) #生成teacher model的random feature matrix F0（固定不变）\n",
    "F = np.random.normal(0,1,(d,p_max))[:,:p] #生成student model的random feature matrix F(d*p)。先按照p_max的大小生成，再根据当前维度p的不同截取前p列形成每个p对应的F。\n",
    "    #注意，这个F对于一般的神经网络是可训练的，但是对于RFM为了简化直接设定为固定值。（固定不变）\n",
    "#teacher parameter w(p) with lambda = ? until each dim of Y~1e0\n",
    "lambda_ = 0.0001\n",
    "#w_0 = np.random.normal(0,sigma/np.sqrt(lambda_*N),p)\n",
    "w_0 = np.random.normal(0,1,p0) #生成teacher model的权重向量（固定不变）\n",
    "#w_0 = np.concatenate((w_0,np.zeros(5)),axis = 0)\n",
    "\n",
    "np.random.set_state(original_random_state)\n",
    "################################################################\n",
    "\n",
    "w = []\n",
    "B = []\n",
    "Y = []\n",
    "for i in tqdm(range(sample_size)):\n",
    "    X = np.random.normal(0,1,(N,d))\n",
    "    X_rf0 = np.tanh(X.dot(F0)/np.sqrt(d))\n",
    "    Y_pure = X_rf0.dot(w_0)\n",
    "    Y_i = Y_pure + np.random.normal(0,sigma,N) #由X通过teacher model（也就是F0和w_0）生成的Y\n",
    "    #S_i = np.concatenate((X,Y_i.reshape(N,-1)),axis=1).reshape(-1)  #S=(X,Y)[0]\n",
    "    B_i = np.tanh(X.dot(F)/np.sqrt(d))\n",
    "    w_i = sample_w(p,N,10,0.5,B_i,Y_i,1)[0]\n",
    "    w.append(w_i)\n",
    "    B.append(B_i)\n",
    "    Y.append(Y_i)\n",
    "w_shuffle = np.random.permutation(w)\n",
    "skl = 0\n",
    "for i in tqdm(range(len(w))):\n",
    "    skl+=log_P(w[i],B[i],Y[i],N,beta,sigma_q)-log_P(w_shuffle[i],B[i],Y[i],N,beta,sigma_q)\n",
    "skl /= len(w)\n",
    "skl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
